# Lab: Xv6 and Unix utilities
## 测试结果
![lab1](images/lab1-pass.png)
## 实验目的

- 熟悉xv6及其系统调用

---

# 1. 启动 xv6

## 实验目的

- 设置计算机以运行实验

## 实验步骤

1. 克隆到本地:
   
   在wsl2下执行：
   
   ```bash
   $ git clone git://g.csail.mit.edu/xv6-labs-2024
   Cloning into 'xv6-labs-2024'
   
   $ cd xv6-labs-2024
   ```
2. 尝试运行xv6：
   
   ```bash
   $ make qemu
   ```
   
   输出：
   
   ```bash
   ···
   xv6 kernel is booting
   
   hart 2 starting
   hart 1 starting
   init: starting sh
   ```
3. 退出qemu:
   同时按下 `Ctrl + a`，再按下 `x`.

# 2. sleep

## 实验目的

在 xv6 操作系统中实现一个用户级的 sleep 程序，接受用户指定的时间参数，使进程暂停运行相应的时长。通过此实验，尝试理解 xv6 系统调用机制、用户程序与内核的交互方式，以及命令行参数的处理方法。

## 实验步骤

1. 阅读 xv6 第一章以及user目录下文件
2. 在 xv6 的 user/ 目录下创建 sleep.c 文件。
3. 根据实验要求以及注意事项，程序需要注意：
   
   - 若参数数量不足，打印错误信息并退出
   - 使用 atoi() 函数将字符串参数转换为整数
   - sleep() 调用返回后，调用 exit(0) 正常退出
4. 在 Makefile 的 UPROGS 变量中添加 sleep 程序，使其能够被编译并加入 xv6 文件系统。
   
   ```bash
   $U/_sleep\
   ```
5. 使用 make qemu 启动 xv6，键入 `sleep`命令测试功能，并使用make grade判断测试是否通过。

## 实验中遇到的问题和解决方法

1. 命令行参数处理错误
   
   - 解决方法：参考 user/echo.c 的实现，了解argc 表示命令行参数的数量（argument count），包括程序本身的名字；argv 是一个字符串数组（argument vector），输入命令行的每个元素都是一个参数
2. `make qemu`时出现链接错误
   
   - 解决方法：在`Makefile`的`UPROGS`中添加`$U/_sleep`，确保编译系统能够识别并编译新程序

## 实验心得

1. 通过查阅 user/usys.S 和 kernel/sysproc.c，了解了用户程序通过`ecall`指令引发trap进入内核态，然后内核trap完成实际功能的流程。
2. 学会了如何正确创建用户程序、处理命令行参数、调用系统调用、如何将新程序添加到 xv6 系统中。

# 3. pingpong

## 实验目的

编写一个用户级程序使用 xv6 系统调用在两个进程之间通过管道进行一字节的"乒乓"通信。通过实践加深对进程间通信、管道机制、进程创建等操作系统概念的理解。

## 实验步骤

### 1. 参考 xv6 的 user/ 目录下的 pipe、fork 等示例程序。

### 2. 在 `user`目录下新建 `pingpong.c`文件。

### 3. 代码实现

- 创建两个管道`parent[2]`和`child[2]`，分别用于父到子、子到父通信。
- 调用 fork() 创建子进程。
- 父进程和子进程各自关闭不需要的管道端口，避免阻塞和资源浪费。
- 父进程向子进程发送一个字节，等待子进程回复。
- 子进程收到字节后，打印`<pid>`: received ping，再回复父进程。
- 父进程收到回复后，打印`<pid>`: received pong。
- 两个进程均在结束前关闭所有用过的管道端口，并调用 exit(0) 正常退出。

### 4. 修改 Makefile

在 Makefile 的 UPROGS 变量中添加：

```c
$U/_pingpong\
```

### 5. 测试

```c
$ make qemu
$ pingpong
```

输出

```c
4: received ping
3: received pong
```

## 实验中遇到的问题和方法

### 问题1：未正确关闭不需要的管道端，导致程序阻塞。

**解决方法**：根据父子进程各自需要的管道端，在 fork 后关闭不需要的端：

- 由于子进程子进程只需要父到子管道的读端和子到父管道的写端，关闭父到子管道的写端和子到父管道的读端
- 父进程只需要父到子管道的写端和子到父管道的读端，关闭父到子管道的读端和子到父管道的写端

## 实验心得

1. 通过实现 pingpong 程序，掌握了管道的基本用法，理解了父子进程如何通过管道进行数据交换，以及父进程先写后读、子进程先读后写的阻塞读写机制可实现进程同步。
2. 及时关闭不需要的管道端口可以防止资源泄漏和死锁。

# 4. primes

## 实验目的

本次实验需要完成一个使用管道和进程协作的并发素数筛选程序。该方案源自Unix管道发明者Doug McIlroy的设计思路，要求在xv6系统中通过创建多个协作进程，构建一个能够高效筛选素数的流水线处理系统。

## 实验步骤

1. 研究基于管道通信的素数筛算法，理解每个素数对应一个独立筛选进程的设计思想:
   
   - 首个处理进程从左侧管道读取数据，识别出第一个素数并输出
   - 随后为每个新发现的素数创建专属进程，负责过滤该素数的倍数
   - 各进程间通过管道连接，形成连续的数据处理链
2. 主函数 `main()`:
   
   - 创建初始管道，用于传递 2~280 的整数序列
   - 创建第一个子进程，负责执行筛选逻辑
   - 父进程向管道中写入待筛选的整数序列
   - 写完数据后关闭管道写端，通知下游处理
   - 等待所有子进程完成工作
3. 实现递归筛选函数 `sieve()`:
   
   - 从输入管道读取第一个数，根据素数筛选法，这必然是素数
   - 打印该素数
   - 创建新管道，用于传递过滤后的数据
   - 创建子进程递归处理下一级筛选
   - 在当前进程中，将不能被当前素数整除的数传递给新管道
   - 注意使用`__attribute__((noreturn))` 避免编译警告
4. 进程注意事项:
   
   - 每个筛选进程仅保留必要的管道端口
   - 使用`close()` 及时关闭不需要的文件描述符
   - 通过检查`read()` 返回值判断数据流结束
   - 用`wait()` 确保子进程正常结束
5. 修改 `Makefile`：
   
   ```bash
   $U/_primes\
   ```
6. 运行测试:
   
   ```bash
   $ make qemu
   $ primes
   
   // 输出2到280的素数
   ```
   
   或在qemu外输入:
   
   ```bash
   $ make GRADEFLAGS=primes grade
   
   primes: OK (2.9s)
   ```

## 遇到的问题及解决方法

1. xv6系统对进程数量和文件描述符有严格限制，若文件描述符泄漏会导致后续进程无法创建管道
   
   - 解决方法：实现中只保留必需的文件描述符：
     
     子进程创建后立即关闭父进程的管道写端：`close(pfd[1])`
     子进程递归调用前关闭不再需要的读端：`close(pfd[0])`
     因为父进程只负责向新创建管道写入数据，关闭该管道的读端，
     数据传输完成后关闭所有剩余管道
2. 需要确保所有衍生进程按正确顺序完成工作，避免子进程提前退出导致管道断裂
   
   - 解决方法：
     
     在每个 `sieve()` 函数中使用 `wait(0)` 等待直接子进程结束
     递归使每个进程负责创建和等待下一级筛选进程
3. 无论在哪个分支，函数都通过 `exit(0)` 结束进程，而不是正常返回
   
   - 解决方法：
     
     添加 `void sieve(int pfd[2]) __attribute__((noreturn))`明确告知编译器此函数不会返回到调用点，消除"控制流到达非void函数末尾"的警告

## 实验心得

素数筛选实现了流水线（pipeline）处理。每个进程接收上游数据，处理后传递给下游，多个进程可以同时工作。不仅提高了计算效率，还自然地将问题分解为可并行处理的子任务。通过这个实验，我更深入地理解了流水线并发的工作原理和优势。

`sieve`函数在进程创建递归调用，每个新得到的素数都会创建一个新的筛选进程，而不需要事先确定进程数量。这种方法展示了递归思想在编程中的妙用。

# 5. find

## 实验目的

实现一个简化版的 UNIX find 程序，用于在 xv6 操作系统中递归查找指定目录树下所有与给定文件名匹配的文件。通过本实验，掌握 xv6 文件系统的目录遍历、递归编程方法以及字符串处理技巧。

## 实验步骤

1. 参考 user/ls.c，学习如何读取目录内容。
2. 编写 find 函数:
   - 递归遍历目录树，查找与目标文件名匹配的文件。
   - 在遍历过程中，跳过 "." 和 ".." 目录，避免死循环。
   - 使用 strcmp 进行字符串比较，避免直接用 ==。

核心代码如下：

```c
void find(char *path, char *filename) {
    // 参数：fd表示打开的目录，de用于存储读取的信息，st用于获取文件类型
    char buf[512], *p;
    int fd;
    struct dirent de;
    struct stat st;

    // 错误检查
    if ((fd = open(path, 0)) < 0) {
        fprintf(2, "无法打开目录 %s\n", path);
        return;
    }

    if ((fstat(fd, &st)) < 0) {
        fprintf(2, "无法获取目录 %s 的状态\n", path);
        close(fd);
        return;
    }

    if (st.type != T_DIR) {
        fprintf(2, "%s 不是一个目录\n", path);
        close(fd);
        return;
    }

    if (strlen(path) + 1 + DIRSIZ + 1 > sizeof buf) {
        fprintf(2, "路径太长\n");
        close(fd);
        return;
    }

    strcpy(buf, path);
    p = buf + strlen(buf);
    *p++ = '/';

    // 遍历当前目录
    while (read(fd, &de, sizeof(de))) {
        // 跳过无效的目录项，只处理实际存在的文件和目录
        if (de.inum == 0) continue;

        memmove(p, de.name, DIRSIZ);
        p[DIRSIZ] = 0;

        if (stat(buf, &st) < 0) {
            fprintf(2, "无法获取文件 %s 的状态\n", buf);
            continue;
        }

        // 跳过当前目录和父目录
        if (strcmp(de.name, ".") == 0 || strcmp(de.name, "..") == 0) continue;

        // 文件名匹配
        if (strcmp(de.name, filename) == 0) {
            printf("%s\n", buf);
        }

        // 递归搜索子目录
        if (st.type == T_DIR) {
            find(buf, filename);
        }
    }

    close(fd);
}
```

3. 在 Makefile 的 UPROGS 中添加 find 程序，确保其能被编译进系统。
4. 测试 find 程序功能。

```bash
$ make GRADEFLAGS=find grade

== Test find, in current directory == find, in current directory: OK (2.6s) 
== Test find, in sub-directory == find, in sub-directory: OK (0.4s) 
== Test find, recursive == find, recursive: OK (1.1s)
```

## 实验中遇到的问题和解决方法

1. C 语言中不能用 == 比较字符串，需用 strcmp。
   
   - 解决方法：
     
     查阅后，改用 strcmp 进行文件名匹配。
2. 在递归进入子目录时，需正确拼接路径。
   
   - 解决方法:
     
     通过缓冲区和指针操作，确保路径格式正确，且不越界。
3. 多次测试后，文件系统中产生了多余文件。
   
   - 解决方法：
     通过 make clean 和 make qemu 重新初始化文件系统，保证测试环境干净。

# 实验心得

通过本次实验，深入理解了 xv6 文件系统的目录结构和遍历方法:

xv6 文件系统采用类 Unix 的层次化目录结构，根目录为 /，其下可以有多个子目录和文件。每个目录本质上是一个特殊的文件，包含若干目录项（dirent），每个目录项记录了文件名和 inode 编号。

1. 打开目录：使用 open() 打开目录，获取文件描述符。
2. 读取目录项：用 read() 逐个读取 struct dirent 结构体，获取每个文件/子目录的名字和 inode。
3. 跳过无效项：如果 dirent.inum == 0，说明该项无效，需跳过。
   跳过特殊目录：目录中总有 "."（当前目录）和 ".."（父目录），遍历时要跳过它们，避免递归死循环。
4. 拼接路径：对子目录递归时，需要将当前路径与子目录名拼接，形成新的完整路径。
5. 判断类型：用 stat() 获取路径对应的 stat 结构体，判断是普通文件还是目录。只有目录才递归。
6. 递归遍历：对子目录递归调用遍历函数，实现整个目录树的遍历。

# 6. xargs

## 实验目的

实现一个简化版的 UNIX xargs 程序，在 xv6 操作系统中实现命令参数的自动拼接与批量执行。通过本实验，掌握标准输入读取、命令行参数拼接、进程创建与管理（fork/exec/wait）等操作系统基本机制。

## 实验步骤

1. 阅读实验要求，理解 xargs 的工作原理：
   - 读取标准输入的每一行，将其作为参数追加到命令后面，然后执行该命令。
2. 代码实现：
   - 复制命令行参数到 argv 数组备用。
   - 逐行读取标准输入（以 \n 结尾），每行作为新参数追加到命令后。
   - 用 fork 创建子进程，子进程用 exec 执行拼接后的命令。
   - 父进程用 wait 等待子进程结束。
   - 注意参数数量不能超过 MAXARG。
3. 在 Makefile 的 UPROGS 变量中添加 xargs。
4. 编译并测试：
   ```bash
   $ echo hello too | xargs echo bye
   bye hello too
   ```

## 实验中遇到的问题和解决方法

1. 不知道如何正确读取标准输入并分割参数：
   - 解决方法：参考 user/echo.c 的参数处理方式，使用 read(0, &c, 1) 逐字符读取，遇到空格或换行分割参数。
2. exec 参数数组溢出：
   - 解决方法：查阅 kernel/param.h，确保参数总数不超过 MAXARG。

## 实验心得

- 管道可将前一个进程的输出作为下一进程的输入，但很多命令不接收管道的传递方式（如echo），其不能直接接收标准输入，而需要接收命令行参数。
  此时需要使用`xargs`命令将管道传输过来的stdin进行处理，然后传递到命令的参数位上。即xargs指令执行: 处理管道左侧的标准输入以及处理后传递到正确的位置上。如果不加xargs指令，则echo命令会提示缺少操作参数。
- xargs命令其实是将管道的标准输入与命令参数拼接为一个新命令行参数。其从输入中读取字符串，直到遇到 \n 或 \r 则停止， 然后将所有读取参数放在一个字符串数组里，将每一行都作为一个参数 fork 出一个子进程来执行 exec 系统调用。

---

# Lab: System Call

## 实验结果
![lab2](images/lab2-pass.png)

## 实验目的

向xv6添加一些新的系统调用，了解它们的工作原理，以及xv6内核的一些内部机制。

---

# 1. Using gdb

## 实验目的

在很多情况下，打印语句足以调试您的内核，但有时单步执行代码或获取堆栈回溯信息会很有用。GDB 调试器可以提供帮助。

## 实验步骤

1. 运行`make qemu-gdb`，然后新建终端中输入`gdb`
2. 输入:

```bash
(gdb) b syscall
断点 1 在 0x80002142：文件 kernel/syscall.c，第 243 行。

(gdb) c
继续。
[切换到线程 1.2]
线程 2 命中断点 1，syscall () 在 kernel/syscall.c:243
243 {
(gdb) layout src
(gdb) backtrace
```

## 实验中遇到的问题和解决方法

1. 运行 `make qemu-gdb`报错：
   
   ```bash
   .gdbinit:2: Error in sourced command file:
   Undefined item: "riscv:rv64".
   ```
   
   - 解决方法：检查系统上安装的GDB版本：
   
   ```bash
   gdb --version && which gdb-multiarch 2>/dev/null || echo "gdb-multiarch未安装"
   ```
   
   删除 `.gdbinit.tmpl-riscv`中 `set architecture riscv`这一行，然后输入 `gdb-multiarch -q`
   并输入 `target remote localhost:26000（输入删掉的端口）`连接到gdb

## 实验心得

熟悉了GDB在操作系统内核调试中的基本工作流程，包括连接远程目标、设置断点、单步执行、检查变量和内存、分析调用栈等；

# 2. system call tracing

## 实验目的

本实验旨在为XV6操作系统内核添加一个系统调用跟踪（`trace`）功能。该功能允许用户程序指定一个跟踪掩码（`mask`），来监控特定系统调用的执行情况。当被跟踪的进程执行掩码中设定的系统调用时，内核将在该系统调用返回前打印一行调试信息，包括进程ID、系统调用名称和返回值。

## 实验步骤

- 准备user调用接口
  
  1. 在`UPROGS` 字段中添加`$U/_trace`，以便编译系统提供的用户态测试程序`trace.c`。
  2. 在`user/user.h` 中声明`trace` 系统调用的用户态函数原型：
  
  ```c
  // 在系统调用列表末尾添加trace系统调用声明
  int trace(int);
  ```
  
  3. 在`user/usys.pl` 的末尾添加`entry("trace");`，生成系统调用的汇编入口点：
  
  ```perl
  # 添加trace系统调用的入口点
  entry("getpid");
  entry("sbrk");
  entry("sleep");
  entry("uptime");
  entry("trace");   # 新增的trace系统调用入口点
  ```
  
  4. 在`kernel/syscall.h` 中为`trace` 分配一个唯一的系统调用号：
  
  ```c
  // 系统调用号定义
  #define SYS_link   19
  #define SYS_mkdir  20
  #define SYS_close  21
  #define SYS_trace  22   // 为trace系统调用分配的唯一系统调用号
  ```
- 实现kernel调用
  
  1. 在`kernel/proc.h` 的`struct proc` 结构中添加一个新字段`tracemask`，用于存储跟踪掩码：
  
  ```c
  // 进程结构体
  struct proc {
    struct spinlock lock;
  
    // p->lock must be held when using these:
    enum procstate state;        // 进程状态
    void *chan;                  // 如果非零，表示进程正在休眠
    int killed;                  // 如果非零，表示进程已被杀死
    int xstate;                  // 退出状态
    int pid;                     // 进程ID
  
    // wait_lock must be held when using this:
    struct proc *parent;         // 父进程
  
    // these are private to the process, so p->lock need not be held.
    uint64 kstack;               // 内核栈的虚拟地址
    uint64 sz;                   // 进程内存大小（字节）
    pagetable_t pagetable;       // 用户页表
    struct trapframe *trapframe; // trampoline.S的数据页
    struct context context;      // 上下文，用于切换到该进程
    struct file *ofile[NOFILE];  // 打开的文件
    struct inode *cwd;           // 当前目录
    char name[16];               // 进程名（用于调试）
    int tracemask;               // 系统调用跟踪掩码，用于存储要跟踪的系统调用
  };
  ```
  
  2. 在`kernel/sysproc.c` 中实现`sys_trace()` 函数，用于设置进程的跟踪掩码：
  
  ```c
  uint64
  sys_trace(void)
  {
    int mask;
  
    // 从系统调用参数中获取跟踪掩码
    argint(0, &mask);
  
    // 设置当前进程的tracemask
    myproc()->tracemask = mask;
  
    return 0;
  }
  ```
  
  3. 在`kernel/syscall.c` 的函数原型声明部分添加`sys_trace` 函数：
  
  ```c
  // 系统调用函数原型
  extern uint64 sys_fork(void);
  extern uint64 sys_exit(void);
  ...
  extern uint64 sys_close(void);
  extern uint64 sys_trace(void);  // 新增的trace系统调用函数声明
  ```
  
  然后在系统调用表中添加 `sys_trace` 函数：
  
  ```c
  // 系统调用号到函数指针的映射表
  static uint64 (*syscalls[])(void) = {
  [SYS_fork]    sys_fork,
  ...
  [SYS_mkdir]   sys_mkdir,
  [SYS_close]   sys_close,
  [SYS_trace]   sys_trace,  // 添加sys_trace函数到系统调用表
  };
  ```
  
  4. 打印跟踪信息：
     
     - 在`kernel/syscall.c` 中创建一个系统调用名称数组：
     
     ```c
     // 系统调用名称数组，用于追踪输出
     static char *syscallnames[] = {
     [SYS_fork]    "fork",
     [SYS_exit]    "exit",
     [SYS_wait]    "wait",
     [SYS_pipe]    "pipe",
     [SYS_read]    "read",
     [SYS_kill]    "kill",
     [SYS_exec]    "exec",
     [SYS_fstat]   "fstat",
     [SYS_chdir]   "chdir",
     [SYS_dup]     "dup",
     [SYS_getpid]  "getpid",
     [SYS_sbrk]    "sbrk",
     [SYS_sleep]   "sleep",
     [SYS_uptime]  "uptime",
     [SYS_open]    "open",
     [SYS_write]   "write",
     [SYS_mknod]   "mknod",
     [SYS_unlink]  "unlink",
     [SYS_link]    "link",
     [SYS_mkdir]   "mkdir",
     [SYS_close]   "close",
     [SYS_trace]   "trace",
     };
     ```
     
     - 修改`syscall()` 函数，实现系统调用跟踪：
     
     ```c
     void
     syscall(void)
     {
       int num;
       struct proc *p = myproc();
     
       num = p->trapframe->a7;  // 获取系统调用号
       if(num > 0 && num < NELEM(syscalls) && syscalls[num]) {
         // 调用对应的系统调用函数，并保存返回值
         uint64 result = syscalls[num]();
         p->trapframe->a0 = result;
     
         // 如果进程的tracemask中对应的位被设置，则输出跟踪信息
         if(p->tracemask & (1 << num)) {
           printf("%d: syscall %s -> %d\n", p->pid, syscallnames[num], (int)result);
         }
       } else {
         printf("%d %s: unknown sys call %d\n",
                 p->pid, p->name, num);
         p->trapframe->a0 = -1;
       }
     }
     ```
- 处理进程派生（Fork）
  
  1. 在 `kernel/proc.c` 的 `fork()` 函数中添加代码，使子进程继承父进程的跟踪掩码：
     
     ```c
     int
     fork(void)
     {
     
     // 复制进程名称
     safestrcpy(np->name, p->name, sizeof(p->name));
     
     // 子进程继承父进程的tracemask
     np->tracemask = p->tracemask;
     
     pid = np->pid;
     
     // ... 省略部分代码 ...
     
     return pid;
     }
     ```
  2. 在 `kernel/proc.c` 的 `allocproc()` 函数中，确保新分配的进程默认不跟踪任何系统调用：
     
     ```c
     static struct proc*
     allocproc(void)
     {
     // ... 省略部分代码 ...
     
     memset(&p->context, 0, sizeof(p->context));
     p->context.ra = (uint64)forkret;
     p->context.sp = p->kstack + PGSIZE;
     
     // 初始化tracemask为0，默认不跟踪任何系统调用
     p->tracemask = 0;
     
     return p;
     }
     ```

## 实验中遇到的问题和解决方法

1. 问题：未定义的trace引用
   
   - 完成初步修改后，运行`make qemu` 出现编译错误，提示无法编译`user/trace.c`，因为找不到`trace` 系统调用的用户态桩代码。
   - 解决方法： 严格按照提示，系统性地添加了所有用户态接口：在`user/user.h` 添加原型，在`user/usys.pl` 添加入口，在`kernel/syscall.h` 添加系统调用号。确保接口在所有层面都已定义。
2. 问题：不清楚内核如何访问用户态参数
   
   - 在实现`sys_trace` 时，不确定如何安全地读取用户传递的整数参数`mask`。
   - 解决方法： 参考`kernel/sysproc.c` 中其他系统调用（如`sys_kill`）的实现，发现内核提供了`argint()`等函数来获取用户态传递的参数。使用`argint(0, &mask)` 成功获取了第一个参数。

## 实验心得

通过这次实验，简要了解xv6的系统调用流程：用户程序通过调用定义在user.h中的函数（如trace()）发起系统调用，这些函数实际上是通过usys.pl脚本生成的汇编代码，将系统调用号放入a7寄存器，然后执行ecall指令进入内核态。CPU执行ecall后进入内核的陷阱处理程序，最终路由到syscall()函数。然后syscall()根据a7寄存器中的系统调用号，从syscalls[]数组中找到对应的处理函数并调用。最后系统调用完成，将结果存入a0寄存器，返回用户态。

# 3. attack xv6

## 实验目的

- 如果系统调用的实现中存在漏洞，攻击者可能会利用该漏洞突破内核与用户程序之间的隔离边界。实验提供了一个xv6的bug，为了了解bug是如何被利用的,实验需要欺骗xv6，获取另一个过程的秘密。

## 实验步骤
如图：

![alt text](images/导出图片.png)

1. 首先观察attacktest的函数:
   1. ```
      if((pid = fork()) < 0) {
          printf("fork failed\n");
          exit(1);   
        }
      if(pid == 0) {
          char *newargv[] = { "secret", secret, 0 };
          exec(newargv[0], newargv);
          printf("exec %s failed\n", newargv[0]);
          exit(1);
        }
      ```
      
      其首先fork子进程，然后exec了secret程序
   2. 根据fork函数内容：
      
      1. ```
         // Allocate process.
           if((np = allocproc()) == 0){
             return -1;
           }
         
           // Copy user memory from parent to child.
           if(uvmcopy(p->pagetable, np->pagetable, p->sz) < 0){
             freeproc(np);
             release(&np->lock);
             return -1;
           }
           np->sz = p->sz;
         ```
         
         1. 首先调用allocproc，为创建子进程做准备
         2. 在allocproc中，
            
            1. 首先调用了kalloc为trapframe分配空间，占1页
            2. 然后分配一个空的页表，这个页表建立到trampoline和trapframe的映射
            3. Xv6采用riscv的sv39模式，采用三级页表，因此proc_pagetable新分配了3页
         3. 将父进程attcaktest的用户页面拷贝到secret中，由于其有4页，所以这一步创建了两个页表页，和4个用户内存页
   3. exec执行secret
      
      1. 在exec中：
         
         ```
         if((pagetable = proc_pagetable(p)) == 0)
            goto bad;

         // Load program into memory.
         for(i=0, off=elf.phoff; i<elf.phnum; i++, off+=sizeof(ph)){
            if(readi(ip, 0, (uint64)&ph, off, sizeof(ph)) != sizeof(ph))
               goto bad;
            if(ph.type != ELF_PROG_LOAD)
               continue;
            if(ph.memsz < ph.filesz)
               goto bad;
            if(ph.vaddr + ph.memsz < ph.vaddr)
               goto bad;
            if(ph.vaddr % PGSIZE != 0)
               goto bad;
            uint64 sz1;
            if((sz1 = uvmalloc(pagetable, sz, ph.vaddr + ph.memsz, flags2perm(ph.flags))) == 0)
               goto bad;
            sz = sz1;
            if(loadseg(pagetable, ph.vaddr, ip, ph.off, ph.filesz) < 0)
               goto bad;
         }
         // ···
         proc_freepagetable(oldpagetable, oldsz);
         ```
         1. 在exec中首先分配一个新的pagetable，根据对于proc_pagetable的分析，这里会新分配3页。
         2. 随后将elf中需要load的段装入内存，secret的elf有两个需要装入的段(代码段和数据段)，各占一页。
         3. 随后分配了两页，一页作为用户栈，一页作为guard
         4. exec的最后释放了旧页表，由于uvmunmap函数并没有释放trapframe的物理内存，因为此时新页表也在映射该内存，并没有分配一个新的页作为trapframe。所以这块释放的只是attacktest的用户内存部分4页+页表5页。
   
   4. secret创建运行，在其运行时调用了sbrk最终调用了growproc，使用户内存增加了32页，由于exec创建了一个用户页表，一个页表页有512页，因此不用分配新的页表页，所以这一步新分配了32页。

   5. secret exit，在attacktest的wait中调用了freeproc释放secret的内存

   6. 随后attacktest调用attack，
   
   由于attack和secret同样都只有4页用户内存，因此在执行attack的时候系统分配的页面数应该与secret时相同，即1(trapframe)+3(proc_pagetable)+6(uvmcopy)+3(proc_pagetable)+4(load)+2(stack & guard) - 9(oldpagetable) = 10页。

   由于xv6使用一个链式栈管理空闲物理内存，secret写入秘密的是分配的32页中的第10页所以其前面有22页+5(pagetable)页，attack一开始占用了10页，所以attack只要分配到第17页读取相应位置就可以得到秘密。

## 实验中遇到的问题和解决方法
1. 不了解如何获取secret写入秘密的页
   - 解决方法：

   查看`attacktest.c`中调用的各个函数的源码，分析分配内存页的过程

2. 不了解attacktest和secret的页数
   - 解决方法：

   通过命令`readelf -l user/_attacktest`得知其用户内存为4页

## 实验心得
这道题的主要思路是利用xv6是利用链式栈管理空闲物理内存的特点，以及这次实验特地加上的bug即kalloc和kfree的时候不会破坏页内的内容，使得attack只要定位并分配到secret写入秘密的页就可以将秘密读出。原理很简单，但是定位secret写入秘密的页并不容易，需要分析清楚进程销毁还有fork和exec过程分配和释放内存的细节。

这个实验也让我思考了权限隔离的重要性，以及如何在系统设计中防止类似的信息泄露漏洞。

---

# Lab: page tables

---

# Inspect a user-process page table
## 实验目的
为了帮助理解RISC-V的页表结构，解释用户进程的页表。
## 实验步骤
1. 输入
```
$ make qemu
$ pgtbltest

print_pgtbl starting
va 0x0 pte 0x21FC885B pa 0x87F22000 perm 0x5B
va 0x1000 pte 0x21FC7C1B pa 0x87F1F000 perm 0x1B
va 0x2000 pte 0x21FC7817 pa 0x87F1E000 perm 0x17
va 0x3000 pte 0x21FC7407 pa 0x87F1D000 perm 0x7
va 0x4000 pte 0x21FC70D7 pa 0x87F1C000 perm 0xD7
va 0x5000 pte 0x0 pa 0x0 perm 0x0
va 0x6000 pte 0x0 pa 0x0 perm 0x0
va 0x7000 pte 0x0 pa 0x0 perm 0x0
va 0x8000 pte 0x0 pa 0x0 perm 0x0
va 0x9000 pte 0x0 pa 0x0 perm 0x0
va 0xFFFF6000 pte 0x0 pa 0x0 perm 0x0
va 0xFFFF7000 pte 0x0 pa 0x0 perm 0x0
va 0xFFFF8000 pte 0x0 pa 0x0 perm 0x0
va 0xFFFF9000 pte 0x0 pa 0x0 perm 0x0
va 0xFFFFA000 pte 0x0 pa 0x0 perm 0x0
va 0xFFFFB000 pte 0x0 pa 0x0 perm 0x0
va 0xFFFFC000 pte 0x0 pa 0x0 perm 0x0
va 0xFFFFD000 pte 0x0 pa 0x0 perm 0x0
va 0xFFFFE000 pte 0x21FD08C7 pa 0x87F42000 perm 0xC7
va 0xFFFFF000 pte 0x2000184B pa 0x80006000 perm 0x4B
print_pgtbl: OK
```

2. print_pgtbl()函数：
```
void
print_pgtbl()
{
  printf("print_pgtbl starting\n");
  for (uint64 i = 0; i < 10; i++) {
    print_pte(i * PGSIZE);
  }
  uint64 top = MAXVA/PGSIZE;
  for (uint64 i = top-10; i < top; i++) {
    print_pte(i * PGSIZE);
  }
  printf("print_pgtbl: OK\n");
}
```
分别打印了前十页页表条目和后十页页表条目.

   1. print_pte函数：
   ```
   void
   print_pte(uint64 va)
   {	//通过系统调用，获取条目
      pte_t pte = (pte_t) pgpte((void *) va);
      printf("va 0x%lx pte 0x%lx pa 0x%lx perm 0x%lx\n", va, pte, PTE2PA(pte), PTE_FLAGS(pte));
   }
   ```

3. 解释：
例如`va 0x0 pte 0x21FC885B pa 0x87F22000 perm 0x5B`

   1. 虚拟地址 (va 0x0)
   2. 页表项 (pte 0x21FC885B，即`0010 0001 1111 1100 1000 1000 0101 1011`)：
      1. 物理页框地址（Physical Page Frame Address）：pte[63:10]

      2. 权限位和控制位：pte[9:0]
         有效位（PTE_V）：1，表示该页表项有效。

         读权限（PTE_R）：1，表示该页是可读的。

         用户访问权限（PTE_X）：1，表示可以执行。

         执行权限（PTE_U）：1，表示该用户态可以访问。

   3. 映射到的物理地址 (pa 0x87F22000)
   4. 权限位 (perm 0x5B，该页的访问权限)
      有效位（PTE_V）：1，表示该页表项有效。

      读权限（PTE_R）：1，表示该页是可读的。

      写权限（PTE_W）：0，不可写。

      用户访问权限（PTE_X）：1，表示可以执行。

      执行权限（PTE_U）：1，表示该用户态可以访问。

## 实验中遇到的问题和解决方法

1. 理解 RISC-V 页表项结构：
   - 解决方法：详细阅读 xv6 书籍第 3 章和 `kernel/riscv.h` 文件，了解页表项的各个位的含义和 RISC-V SV39 虚拟内存系统的设计。

## 实验心得

通过本实验，我深入理解了 RISC-V 的页表结构和 xv6 的内存管理机制：

1. RISC-V SV39 虚拟内存系统使用三级页表，每个页表项占 64 位，但实际只使用 54 位（44 位物理页号 + 10 位标志位）。

2. 页表项中，最低位（第 0 位）是有效位（PTE_V），它决定了这个页表项是否有效。如果该位为 0，则其他位都将被忽略。

# Speed up system calls
## 实验目的
某些操作系统（例如 Linux）通过在用户空间和内核之间共享只读区域的数据，来加快某些系统调用的速度。这样在执行这些系统调用时就无需进行内核跨越操作。为了了解如何在页表中插入映射，需要为 xv6 中的 getpid() 系统调用实现这一优化。

## 实验步骤

1. 在 `memlayout.h` 中可以看到 `USYSCALL` 的定义位置和 `struct usyscall` 的结构：

   ```c
   // User memory layout:
   // ...
   // USYSCALL (shared with kernel)
   // TRAPFRAME (p->trapframe, used by the trampoline)
   // TRAMPOLINE (the same page as in the kernel)
   #define TRAPFRAME (TRAMPOLINE - PGSIZE)
   #define USYSCALL (TRAPFRAME - PGSIZE)
   
   struct usyscall {
     int pid;  // Process ID
   };
   ```

   - 在 `proc.h` 中进程结构体已添加了对应的字段：
   
   ```c
   struct proc {
     // ...
     struct usyscall *usyscall; // fast system call
   };
   ```

2. 在 `proc.c` 的 `allocproc()` 函数中，为每个新创建的进程分配 usyscall 页面：

   ```c
   // 分配用户系统调用结构
   if ((p -> usyscall = (struct usyscall *)kalloc()) == 0) {
     freeproc(p);
     release(&p->lock);
     return 0;
   }
   p->usyscall->pid = p->pid;
   ```

3. 在 `proc.c` 的 `proc_pagetable()` 函数中，将 usyscall 页面映射到用户空间：

   ```c
   // map usyscall page below trapframe - for fast userpace system calls
   if(mappages(pagetable, USYSCALL, PGSIZE,
             (uint64)(p->usyscall), PTE_R | PTE_U) < 0){
     uvmunmap(pagetable, TRAMPOLINE, 1, 0);
     uvmunmap(pagetable, TRAPFRAME, 1, 0);
     uvmfree(pagetable, 0);
     return 0;
   }
   ```

   - 这里设置的权限是 `PTE_R | PTE_U`，表示用户空间可读但不可写

4. 在 `proc.c` 的 `freeproc()` 函数中，释放 usyscall 页面的物理内存：

   ```c
   if(p->usyscall)
     kfree((void*)p->usyscall);
   p->usyscall = 0;
   ```

   - 在 `proc.c` 的 `proc_freepagetable()` 函数中，解除 usyscall 页面的映射：

   ```c
   #ifdef LAB_PGTBL
     uvmunmap(pagetable, USYSCALL, 1, 0);
   #endif
   ```

5. 在 `ulib.c` 中，实现了 `ugetpid()` 函数，直接从映射的 usyscall 页面读取 pid：

   ```c
   int
   ugetpid(void)
   {
     struct usyscall *u = (struct usyscall *)USYSCALL;
     return u->pid;
   }
   ```

6. 测试：
   - 使用 `make qemu` 编译并运行 xv6
   - 运行 `pgtbltest` 测试程序
   - 输出为 `ugetpid_test: OK`

## 实验中遇到的问题和解决方法

1. 问题：不确定应该设置什么权限位
   - 解决方法：查阅 `kernel/riscv.h` 中的权限定义，选择 `PTE_R | PTE_U`（只读且用户可访问）

2. 问题：编译器报错
```
未定义标识符 "USYSCALL"
不允许使用指向不完整类型 "struct usyscall" 的指针或引用
```

- 原因：

在用户空间代码中使用了内核定义的符号和结构体，而这些符号和结构体在正常情况下对用户程序是不可见的。

- 解决方法：

根据测试，这个报错不影响编译。因为Makefile告诉编译器定义这些宏,因此在实际编译过程中，条件编译的代码被正确包含。

## 实验心得

通过这个实验，我理解了系统调用优化的一种重要方法：通过在用户空间和内核之间共享只读内存，避免频繁的内核态切换。传统的系统调用需要通过陷阱（trap）进入内核态，而优化后的 `ugetpid()` 只需读取映射到用户空间的内存，这大大减少了开销。实验结果表明，该方法能够大幅提升特定系统调用的执行效率，也为今后系统调用的设计与优化提供了有价值的实践依据。同时，实验中的报错也让我深刻感受到实践的重要。

# Print a page table
## 实验目的

本实验的主要目标是实现一个能够可视化 RISC-V 页表内容的函数，通过打印页表的具体信息来加深对 RISC-V 内存管理机制的理解，并为后续的内核调试工作提供便利。具体任务包括编写 `vmprint()` 函数，以特定格式递归输出页表的各级条目，包括虚拟地址、PTE 内容及其对应的物理地址。

## 实验步骤

1. 根据之前的实验，了解 RISC-V 采用三级页表结构（Sv39），通过虚拟地址的高位索引顶级页表（Level 2），中间级页表（Level 1）和底层页表（Level 0）。每个页表条目（PTE）包含物理地址帧号和标志位。

2. 输出格式要求： 
```
page table 0x0000000087f22000
 ..0x0000000000000000: pte 0x0000000021fc7801 pa 0x0000000087f1e000
 .. ..0x0000000000000000: pte 0x0000000021fc7401 pa 0x0000000087f1d000
 .. .. ..0x0000000000000000: pte 0x0000000021fc7c5b pa 0x0000000087f1f000
 .. .. ..0x0000000000001000: pte 0x0000000021fc70d7 pa 0x0000000087f1c000
 .. .. ..0x0000000000002000: pte 0x0000000021fc6c07 pa 0x0000000087f1b000
 .. .. ..0x0000000000003000: pte 0x0000000021fc68d7 pa 0x0000000087f1a000
 ..0xffffffffc0000000: pte 0x0000000021fc8401 pa 0x0000000087f21000
 .. ..0xffffffffffe00000: pte 0x0000000021fc8001 pa 0x0000000087f20000
 .. .. ..0xffffffffffffd000: pte 0x0000000021fd4c13 pa 0x0000000087f53000
 .. .. ..0xffffffffffffe000: pte 0x0000000021fd00c7 pa 0x0000000087f40000
 .. .. ..0xfffffffffffff000: pte 0x000000002000184b pa 0x0000000080006000
``` 
   - 第一行输出页表基地址。  
   - 每行输出一个有效的 PTE，缩进深度反映其所在层级（顶级无缩进，每加深一级增加一个“ ..”）。  
   - 每行包含虚拟地址、PTE 的十六进制值和对应的物理地址。
   - 简而言之，就是将每一级的页表，给他按照树的形式打印出来

3. 实现 `vmprint()` 函数：  
   - 使用递归方式遍历页表树，逐级处理有效的 PTE。怎么实现递归呢？根据提示参考`freewalk`函数：
   ```
   void
   freewalk(pagetable_t pagetable)
   {
   // 页表有 2^9 = 512 个页表项（PTE）
   for(int i = 0; i < 512; i++){
      pte_t pte = pagetable[i];
      // 如果该页表项有效 (PTE_V) 且不是叶子节点（没有 R/W/X 权限）
      if((pte & PTE_V) && (pte & (PTE_R | PTE_W | PTE_X)) == 0){
         // 当前页表项指向的是下一级页表
         uint64 child = PTE2PA(pte);             // 获取子页表的物理地址
         freewalk((pagetable_t)child);           // 递归释放子页表
         pagetable[i] = 0;                        // 清空当前页表项
      } 
      // 如果是有效的叶子节点（即具有 R/W/X 权限）
      else if(pte & PTE_V){
         // 不允许释放包含实际映射的叶子节点
         panic("freewalk: leaf");
      }
   }
   // 释放当前这一页页表
   kfree((void*)pagetable);
   }
   ```
   有以下思路：
   - 若PTE_V = 1(页表项有效)，打印信息。
   - 如果PTE不是叶子节点（即不包含PTE_R, PTE_W, PTE_X任何权限位），则是一个指向下一级页表的指针，我们需要递归遍历下一级页表。

   据此实现递归函数`vmprint_re`：
   ```
   void 
   vmprint_re(pagetable_t pagetable, int level, uint64 va) {
   uint64 sz;
   // 为什么va使用uint64？因为要打印前缀，而前缀可能超过32位
   // 错误处理
   if(pagetable == 0) {
      printf("vmprint_re: null pagetable\n");
      return;
   }
   if(level < 0) {
      return;
   }

   // 根据level计算当前页表的映射范围
   if(level == 2) {
      sz = 512 * 512 * PGSIZE; // 1GB
   } else if(level == 1) {
      sz = 512 * PGSIZE; // 2MB
   } else {
      sz = PGSIZE; // 4KB
   }

   // 遍历当前页表的512个PTE
   for(int i = 0; i < 512; i++) {
      pte_t pte = pagetable[i];
      if ((pte & PTE_V) == 0) {
         continue; // 无效PTE，跳过
      }
      // 打印前缀
      for (int j = 0; j < (3 - level); j++) {
         printf(" ..");
      }
      uint64 curr_va = va + i * sz; // 计算当前PTE对应的虚拟地址
      // 为什么当前PTE对应的虚拟地址是va + i * sz？
      // 因为va是当前页表的起始虚拟地址，i是PTE索引，sz是当前页表的映射范围
      // 打印当前页表项信息
      printf("0x%lx: pte 0x%lx pa 0x%lx\n", 
         curr_va, pte, PTE2PA(pte));
      // 递归处理下一级页表
      // 不是叶子节点才递归
      if ((pte & (PTE_R | PTE_W | PTE_X)) == 0) {
         vmprint_re((pagetable_t)PTE2PA(pte), level - 1, curr_va);
      }
   }
   }
   ```

   在`vmprint`中调用该函数：
   ```
   void
   vmprint(pagetable_t pagetable) {
   printf("page table %p\n", pagetable);
   vmprint_re(pagetable, 2, 0); 
   }
   ```

4. 测试验证：  
   - 输入`make qemu`后输入`pgtbltest`系统调用触发 `vmprint()`，输出结果:
   ![print-table](images/print-table-pass.png)

---

## 三、实验中遇到的问题和方法

1. va和sz（起始地址和范围）的数据类型
   - 由于RISC-V Sv39使用39位虚拟地址，前缀可能超过32位
   - 使用uint64代替int

2. 计算当前PTE对应的虚拟地址
   - va + i * sz，其中va是当前页表的起始虚拟地址，i是PTE索引，其在循环中递增，sz是当前页表的映射范围

3. 打印当前页表项信息
   - 使用%p输出非指针类型值PTE2PA(pte)
   - 查阅发现其为长无符号整数的十六进制，改为%lx
---

## 四、实验心得

通过实现页表遍历，进一步掌握了多级页表的组织方式、虚拟地址到物理地址的转换过程，以及 PTE 标志位的具体作用。页表的树形结构非常适合递归处理，但需注意终止条件和状态传递（如当前深度和虚拟地址的累积计算）。其中内核中提供的宏（如 `PTE2PA`、`PX`）极大简化了地址计算和标志判断，避免了手动位操作的错误。

---

# 
